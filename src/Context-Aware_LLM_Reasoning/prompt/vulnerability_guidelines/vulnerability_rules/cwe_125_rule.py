CWE_125_RULE = """
[CWE-125 Reference Guideline | Out-of-bounds Read | Non-binding, Evidence-first]

Overview
- CWE-125 occurs when a product reads data past the end, or before the beginning, of the intended buffer.
- This can lead to information disclosure, crashes, undefined behavior, and sometimes security-critical downstream effects (e.g., leaking secrets that enable further exploitation).
- In partial snippets, the absence of visible bounds checks is not proof of vulnerability. Use this guideline to form hypotheses and identify code evidence that would confirm or refute them.

What counts as "out-of-bounds read" (static analysis framing)
- Out-of-bounds read:
  - Reading memory outside the valid range of a buffer (array/string/allocated region), either before index 0 or beyond the last valid element.
  - Can occur via indexing, pointer arithmetic, length miscalculation, or library calls that read until a terminator that may be missing.
- Buffer:
  - A contiguous memory region with a defined extent (fixed-size array, heap allocation, stack buffer, or a view/slice with length metadata).

Where out-of-bounds reads typically occur (sensitive sinks)
- Indexing into arrays/buffers/strings:
  - `buf[i]`, `arr[idx]`, pointer-based reads `*(p + i)` where `i`/`idx` can be out of range.
- Length-driven parsing:
  - Loops that advance a cursor without ensuring remaining length.
- String/byte scanning:
  - Reads that assume a terminator exists (e.g., NUL) and keep reading until it’s found.
- Copy/compare routines that read:
  - `memcmp`, `strcmp`, parsing helpers that may read `n` bytes based on untrusted `n` or miscomputed sizes.
- Boundary-crossing APIs:
  - Reading from files/network into a buffer, then reading from the buffer using lengths derived from the input.

Common failure modes (reasoning hints, not assumptions)
- Missing bounds checks on read indices:
  - `i`, `idx`, `offset`, `len` not validated against buffer size.
- Incorrect size/length computation:
  - Off-by-one errors, wrong unit (bytes vs elements), integer overflow/underflow when computing offsets.
- Trusting external length fields:
  - Using an untrusted length from input (protocol/header) to drive reads without validation.
- Pointer arithmetic without range validation:
  - Cursor moves beyond allocated region due to logic bugs.
- Sentinel/terminator assumptions:
  - Assuming a string is NUL-terminated or a delimiter exists, then scanning past buffer end.

What “proper bounds discipline” looks like (context-specific)
- Explicit range checks before every read:
  - Ensure `0 <= idx < size` (or equivalent) at the point of use.
- Centralized length tracking:
  - Maintain `(base_ptr, length, cursor)` and enforce `cursor + needed <= length`.
- Safer APIs and contracts:
  - Prefer bounds-aware functions and pass explicit lengths; avoid APIs that depend on terminators when input may be non-terminated.
- Defensive parsing:
  - Validate all externally-supplied sizes/offsets; reject or clamp invalid values early.
- Clear invariants:
  - Document and preserve invariants like “cursor always points within [0, len]”.

Common weak/insufficient defenses (signals of possible risk)
- Relying on “it should be well-formed”:
  - Implicit trust that input lengths/terminators exist.
- Check in one place, use in another:
  - Validation far from the read site, with intervening transformations that can invalidate it.
- Partial checks:
  - Checking only lower bound or only upper bound, or checking `idx <= size` instead of `idx < size`.
- Type pitfalls:
  - Signed/unsigned conversions that turn negative indices into huge values.

Evidence to look for in code (static snippet oriented)
- Strong evidence of mitigation:
  - Bounds checks adjacent to read sites (same block / immediately before read).
  - Cursor-based parsing with consistent `remaining` checks.
  - Validated length fields with explicit constraints (min/max) before use.
  - Use of APIs that require explicit lengths and return status on insufficient data.
- Evidence suggesting vulnerability:
  - Reads using indices/offsets derived from external input with no visible validation.
  - Loops that read until a delimiter/terminator with no cap.
  - Computations like `ptr = base + offset` followed by reads, without validating `offset` and `offset + need`.
  - Off-by-one patterns (e.g., reading `buf[len]`).
  - Integer overflow/underflow in `size + offset`, `len - headerSize`, `idx * elemSize` prior to reads.

How to use this guideline under incomplete context
- Identify buffer(s) and their known extent:
  - Is size known (constant/`sizeof`/tracked variable), or Unknown?
- Identify read sites and the index/offset provenance:
  - Is `idx/len/offset` influenced by user input, file/network data, or arithmetic that can overflow?
- Generate a small number of targeted hypotheses:
  - H1: Index/offset used for read can exceed buffer bounds due to missing/incorrect checks.
  - H2: Parser cursor can advance past end under malformed input (length field / delimiter assumptions).
  - H3: Size math (including signed/unsigned) can overflow/underflow, breaking bounds reasoning.
  - H4: Bounds checks exist outside the snippet (helpers/framework) → Unknown without evidence.
- For each hypothesis, specify:
  (a) evidence in the snippet supporting it (e.g., direct indexing, untrusted length usage),
  (b) evidence needed to confirm it (e.g., adjacent checks, validated length invariants),
  (c) counter-evidence that would refute it (e.g., explicit `idx < size`, `remaining >= need`).

Quick red flags in partial code (weak → strong)
- Strong: Direct buffer reads using externally-influenced `idx/len/offset` with no adjacent bounds checks.
- Medium: Bounds checks exist but appear off-by-one, incomplete, or rely on fragile assumptions (terminator/delimiter).
- Medium: Arithmetic on sizes/offsets uses mixed signed/unsigned or can overflow before the read.
- Weak: Bounds discipline might be implemented in omitted helpers/parsers → treat as Unknown and reduce confidence.
"""
if __name__ == "__main__":
    print(CWE_125_RULE)
