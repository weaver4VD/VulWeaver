CWE_95_RULE = """
[CWE-95 Reference Guideline | Dynamic Evaluation Injection (Eval Injection) | Non-binding, Evidence-first]

Overview
- CWE-95 occurs when a product receives externally-influenced input from an upstream component and uses it in a dynamic evaluation call (e.g., "eval") without correct neutralization of code syntax, allowing the input to be interpreted as executable code.
- CWE-95 is a concrete, eval-centric instance of code injection risk: the defining feature is the presence of a dynamic evaluation API that interprets strings as code or expressions.
- In partial snippets, missing neutralization evidence is not proof of vulnerability. Use this guideline to form hypotheses and identify code evidence that would confirm or refute them.

What counts as “externally-influenced input” (typical sources)
- HTTP-derived data: parameters, headers, cookies, path variables, request bodies.
- Persisted user content: DB-stored fields later fed into dynamic evaluation.
- Cross-component payloads: message/RPC fields only if attacker-controllable in context.
- File-based sources: uploaded scripts/templates/configs later evaluated as code.

Dynamic evaluation sinks (typical in Java and JVM ecosystems)
- Script engines:
  - javax.script.ScriptEngine#eval(...)
  - Nashorn/GraalJS/Rhino integrations (when present)
- Expression evaluators used like eval:
  - SpEL/OGNL/MVEL/JEXL/GroovyShell.evaluate (depending on imports/frameworks)
- Template engines with executable directives/macros when user input influences the template body
- Any custom “evaluate/executeExpression” helper that forwards to one of the above

Core risk mechanism (eval as a downstream interpreter)
- Dynamic evaluation treats a string as code/expression; special tokens become executable syntax:
  - quotes, parentheses, operators, separators, property/method access, function calls, imports/includes, interpolation markers.
- Injection happens when user input is placed in a code context such that it can:
  - break out of an intended literal/context boundary, or
  - introduce new expressions/statements, or
  - access sensitive objects/methods exposed to the evaluator.

What “proper neutralization/restriction” looks like (context-specific)
- Prefer not to use eval:
  - Replace dynamic evaluation with fixed logic and safe parameter passing.
- If dynamic evaluation is necessary:
  - Do not build eval strings via concatenation with untrusted input.
  - Pass user data via bindings/variables (data-only) rather than embedding it into code text.
  - Restrict the evaluation language capabilities:
    - allow-list permitted functions/operators/variables,
    - disable or block reflective access / class loading / method invocation features where possible,
    - expose only minimal safe objects to the evaluation context.
- Constrain input to a safe subset:
  - Use strict allow-list patterns or parse a limited DSL; treat blacklists as weak.

Common weak/insufficient defenses (signals of possible risk)
- Directly evaluating user input:
  - eval(userInput) or engine.eval(userInput) where userInput is externally influenced.
- Concatenating user input into eval strings:
  - "safePrefix(" + userInput + ")" and then eval(...)
- Blacklist filtering of a few keywords/characters:
  - removing "import", ";", or a small set of operators is bypassable.
- Wrong-context escaping:
  - HTML escaping or URL encoding does not prevent eval injection.
- Validate-then-transform pitfalls:
  - Validate raw input, then decode/normalize/replace later, producing executable tokens.

Evidence to look for in code (static snippet oriented)
- Strong evidence of mitigation:
  - No eval/dynamic evaluation in the dataflow from untrusted input.
  - Eval is used only on fixed, developer-controlled code; user input is passed as bound variables (data-only).
  - Clear allow-listing/DSL parsing that prevents arbitrary code syntax, plus restricted evaluation context.
  - The evaluator context exposes only minimal safe objects and forbids reflective/class access (when visible).
- Evidence suggesting vulnerability:
  - Externally influenced input flows into eval/evaluate APIs as code text.
  - User input affects the structure of the evaluated expression (not just variable values).
  - “Sanitization” is limited to partial stripping/blacklisting with unclear completeness.

How to use this guideline under incomplete context
- First identify the evaluator:
  - Which engine/library performs the dynamic evaluation (ScriptEngine, SpEL, OGNL, Groovy, etc.)?
- Generate a small number of targeted hypotheses based on observed pattern:
  - H1: Untrusted input is executed directly by eval (high risk).
  - H2: Untrusted input is embedded into a larger eval string, enabling syntax break-out.
  - H3: Strong restrictions/bindings exist in helper/config not shown here.
- For each hypothesis, specify:
  (a) evidence in the snippet supporting it (eval call site, input flow, concatenation),
  (b) evidence needed to confirm it (binding usage, exposed objects, sandbox config, allowed grammar),
  (c) counter-evidence that would refute it (only fixed code evaluated; user input bound as variables; strict DSL + allow-list).

Quick red flags in partial code (weak → strong)
- Strong: request-derived/persisted user data passed directly into eval/evaluate APIs.
- Strong: user input concatenated into an expression that is dynamically evaluated.
- Medium: blacklist-style “sanitization” around the eval string.
- Medium: decoding/normalization occurs after validation and before evaluation.
- Weak: evaluation is wrapped by helpers/config not shown → treat as Unknown and reduce confidence.
"""
if __name__ == "__main__":
    print(CWE_95_RULE)