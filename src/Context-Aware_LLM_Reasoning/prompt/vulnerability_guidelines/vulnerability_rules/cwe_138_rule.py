CWE_138_RULE = """
[CWE-138 Reference Guideline | Improper Neutralization of Special Elements (Generic Control/Syntax Markers) | Non-binding, Evidence-first]

Overview
- CWE-138 occurs when a product receives input from an upstream component and forwards it (or embeds it) into an output/message for a downstream component, but fails to neutralize (or incorrectly neutralizes) special elements that the downstream component interprets as control elements or syntactic markers.
- This is a generic “structure-breaking” risk: the downstream component may parse the data as a command, query, markup, record, protocol frame, or other structured grammar.
- In partial snippets, missing neutralization evidence is not proof of vulnerability. Use this guideline to form hypotheses and identify code evidence that would confirm or refute them.

What counts as “upstream input” (typical sources)
- HTTP-derived data: parameters, headers, cookies, path variables, request bodies.
- Persisted user content: DB-stored fields forwarded into downstream messages later.
- Cross-component payloads: message/RPC fields only if attacker-controllable in context.
- File-based inputs/metadata: uploaded content/names later embedded into structured outputs.

Downstream components & interpreters (typical sink categories)
- Command-like interpreters: OS command execution, script engines, expression evaluators.
- Query interpreters: SQL/LDAP/XPath/NoSQL query languages.
- Markup/document parsers: HTML/XML/JSON/YAML/CSV and custom structured documents.
- Protocol/message parsers: HTTP headers, email headers, log formats, custom delimiter-based protocols.
- Template/render engines: server-side templates, report generators, config/template processors.

Special elements (control/syntax markers) to think about (reasoning hints, not assumptions)
- Delimiters and separators: quotes, commas, semicolons, pipes, newlines, brackets, braces.
- Escape and comment tokens: backslashes, comment markers, interpolation markers.
- Grammar operators: boolean operators, union/concatenation operators, assignment markers.
- Format-specific tokens:
  - HTML/XML: <, >, &, quotes
  - JSON: quotes, backslashes, control chars
  - CSV: separators, quotes, newlines
  - Shell: separators/operators/quoting rules
  - SQL/XPath/LDAP: quotes/operators/comments

What “proper neutralization/restriction” looks like (context-specific)
- Prefer safe-by-construction interfaces:
  - Use serializers/builders that separate data from syntax (JSON/XML builders, parameter binding, argv-based command execution).
  - Use frameworks with correct auto-escaping in the right output contexts.
- Apply context-appropriate encoding/escaping at the boundary:
  - Choose escaping/encoding that matches the exact downstream grammar and insertion context (string literal vs attribute vs identifier vs field).
  - Apply neutralization after decoding/normalization and immediately before sending to the downstream component.
- Constrain input when feasible:
  - Enforce allow-lists for fields that should be identifiers/enums/IDs, reducing exposure to syntax markers.
  - Avoid allowing upstream input to control structural positions (operators, field names, directives).

Common weak/insufficient defenses (signals of possible risk)
- String concatenation/interpolation into structured outputs:
  - Constructing commands/queries/documents/records by joining raw input into syntax strings.
- Blacklist filtering:
  - Stripping a few characters/tokens is often bypassable and format-dependent.
- Wrong-context escaping:
  - Using HTML escaping for JSON, URL encoding for SQL, etc.
- Validate-then-transform pitfalls:
  - Validate raw input, then decode/normalize/replace later, reintroducing special markers.
- Assuming sanitization happens elsewhere without evidence:
  - Treat upstream sanitization as Unknown if not shown in snippet.

Evidence to look for in code (static snippet oriented)
- Strong evidence of mitigation:
  - Use of structured builders/serializers, parameter binding, or tokenized APIs that keep data separate from control syntax.
  - Explicit, clearly context-matched encoding/escaping applied right before the sink.
  - Strict allow-list constraints on inputs that would otherwise affect downstream syntax or structure.
- Evidence suggesting vulnerability:
  - Externally influenced input is embedded into a structured message/command/query/document via concatenation or templating without clear context-appropriate neutralization.
  - “Sanitization” is generic or blacklist-based with unclear target grammar.
  - Input influences control positions (operators, directives, field names) rather than value-only positions.

How to use this guideline under incomplete context
- First identify the downstream component category implied by sinks/imports:
  - command vs query vs markup vs protocol vs template.
- Generate a small number of targeted hypotheses based on observed construction patterns:
  - H1: Upstream input can introduce control/syntax markers that alter downstream parsing.
  - H2: Neutralization exists but is wrong-context or incomplete for the downstream grammar.
  - H3: Proper neutralization/structured building occurs in helpers/framework defaults not shown here.
- For each hypothesis, specify:
  (a) evidence in the snippet supporting it (string building, sink usage, context indicators),
  (b) evidence needed to confirm it (exact sink/parser, encoding function semantics, where normalization occurs),
  (c) counter-evidence that would refute it (structured builder/binding/tokenized API, strict allow-lists).

Quick red flags in partial code (weak → strong)
- Strong: user-influenced data concatenated into a structured message that is parsed/interpreted by a downstream component.
- Medium: presence of ad-hoc “replace/remove” sanitization with unclear completeness or wrong target context.
- Medium: transformations occur after any escaping/encoding step.
- Weak: sanitization may exist outside the shown function → treat as Unknown and reduce confidence.
"""

if __name__ == "__main__":
    print(CWE_138_RULE)