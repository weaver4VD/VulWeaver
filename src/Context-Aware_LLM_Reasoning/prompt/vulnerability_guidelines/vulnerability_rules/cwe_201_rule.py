CWE_201_RULE = """
[CWE-201 Reference Guideline | Sensitive Information in Sent Data | Non-binding, Evidence-first]

Overview
- CWE-201 occurs when a product transmits data to another actor (client, user, external service, log-like channel, or any recipient) but the transmitted payload includes sensitive information that the recipient should not be able to access.
- This is an information exposure problem: the risk is not “taint changes syntax” (injection), but “data crosses a boundary to an unintended/over-broad audience”.
- In partial snippets, missing redaction/access-control evidence is not proof of vulnerability. Use this guideline to form hypotheses and identify code evidence that would confirm or refute them.

What counts as “sensitive information” (examples; context-dependent)
- Authentication secrets: passwords, password hashes (depending on threat model), session tokens, API keys, OAuth tokens, JWT signing keys, reset tokens.
- Cryptographic material: private keys, secret keys, seed values, nonces if misuse is possible, key material in configs.
- Personal data: email/phone/address, government IDs, health/financial data, user profile data not meant for the recipient.
- Internal/security metadata: stack traces with secrets, internal hostnames, filesystem paths, database connection strings, security configuration details.
- Derived sensitive data: full objects that include sensitive fields when serialized (e.g., user entity includes passwordHash).

What counts as “sent data” (typical sinks / transmission channels)
- HTTP responses to clients:
  - response bodies (JSON/XML/HTML), headers, cookies
  - error responses and exception mappers returning details
- Server-to-server outbound requests:
  - HTTP clients, RPC calls, message queues, emails, webhooks
- Client-facing rendering:
  - templates/views that embed server-side objects
- Any serialization boundary:
  - JSON serialization of objects/DTOs, XML marshalling, custom toString output included in responses

Typical root causes (reasoning hints, not assumptions)
- Over-sharing: returning full internal objects/entities instead of a minimal DTO/view model.
- Missing redaction: sensitive fields not removed/masked before serialization.
- Confused audience: data intended for internal use is sent to external clients or lower-privileged users.
- Error/debug exposure: returning exception messages/stack traces/config dumps containing secrets.
- Indirect inclusion: sensitive info concatenated into response strings or embedded in structured outputs.

What “proper restriction” looks like (context-specific)
- Minimize and scope the payload:
  - Use dedicated response models/DTOs that include only fields needed by the recipient.
  - Avoid serializing domain entities directly if they contain sensitive fields.
- Redact/mask sensitive fields:
  - Remove secrets entirely; if partial display is required, mask (e.g., last 4) with clear policy.
- Enforce audience/authorization boundaries:
  - Ensure the recipient is authorized to receive the specific sensitive fields (role/ownership checks).
  - Avoid using user-controlled parameters to select which sensitive fields to include.
- Control error disclosure:
  - Return generic error messages to untrusted recipients; keep detailed diagnostics internal.

Common weak/insufficient defenses (signals of possible risk)
- Relying on “it’s internal” assumptions without evidence of access control or trust boundary.
- Returning/serializing entire objects that likely contain sensitive fields (e.g., User, Account, Config) with default serializers.
- “Masking” that still exposes too much (e.g., returning full tokens in logs/headers), or masking applied inconsistently.
- Conditional debug behavior controlled by user input or environment not clearly restricted.

Evidence to look for in code (static snippet oriented)
- Strong evidence of mitigation:
  - Explicit selection of non-sensitive fields into a response DTO/map.
  - Explicit removal/masking of sensitive fields before sending/serializing.
  - Clear authorization gating for sensitive data exposure paths.
  - Generic error responses that avoid leaking internal details.
- Evidence suggesting vulnerability:
  - Sensitive-looking variables/fields (token/key/password/secret/privateKey) are included in response bodies/headers or outbound payloads.
  - Direct serialization of rich objects/entities that include sensitive fields, especially in JSON responses.
  - Error handlers returning exception messages/stack traces or config values to clients.

How to use this guideline under incomplete context
- Identify the trust boundary and the recipient:
  - Who is the “other actor” (end-user, authenticated user, external service)? Is the channel client-facing?
- Generate a small number of targeted hypotheses based on observed send/serialize behavior:
  - H1: A response/outbound payload includes sensitive fields without redaction.
  - H2: Object serialization leaks sensitive fields implicitly (default JSON/XML serialization).
  - H3: Authorization checks exist outside the shown snippet, but are not visible here.
- For each hypothesis, specify:
  (a) evidence in the snippet supporting it (what data is assembled and where it is sent),
  (b) evidence needed to confirm it (object schema, serializer config, access control checks),
  (c) counter-evidence that would refute it (DTO usage, explicit redaction, clear auth gating).

Quick red flags in partial code (weak → strong)
- Strong: secrets/tokens/keys/password-related fields are placed into HTTP responses, headers, cookies, or outbound messages.
- Medium: direct serialization of user/account/config objects with unknown field exposure.
- Medium: error responses include detailed exception/config data that may contain secrets.
- Weak: redaction/authorization may occur in filters/serializers/controllers not shown → treat as Unknown and reduce confidence.
"""
if __name__ == "__main__":
    print(CWE_201_RULE)
