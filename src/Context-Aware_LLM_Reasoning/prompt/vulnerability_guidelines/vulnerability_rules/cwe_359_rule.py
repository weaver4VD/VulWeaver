CWE_359_RULE = """
[CWE-359 Reference Guideline | Exposure of Private Personal Information | Non-binding, Evidence-first]

Overview
- CWE-359 occurs when a product fails to prevent private personal information (PPI/PII) from being accessed by an unauthorized actor, or by an actor who lacks the person’s implicit consent for that access.
- This is an information exposure issue centered on *privacy boundaries*: who can access which person’s data, under what consent/authorization rules.
- In partial snippets, missing privacy/consent enforcement evidence is not proof of vulnerability. Use this guideline to form hypotheses and identify code evidence that would confirm or refute them.

What counts as private personal information (examples; context-dependent)
- Direct identifiers:
  - full name, email, phone, address, government IDs, student IDs, employee IDs
- Sensitive personal data:
  - health/medical info, financial info, location history, contact lists, private messages
- Account-linked metadata:
  - account numbers, usernames tied to real identity, unique identifiers that enable profiling
- Combined/derived identifiers:
  - datasets that become identifying when combined (quasi-identifiers), user analytics tied to identity
- Authentication-related user data (sometimes overlaps with CWE-201):
  - session identifiers, password reset details (depending on context), but CWE-359 focuses on privacy exposure to unauthorized actors

Unauthorized actor and consent boundary (static analysis framing)
- Unauthorized actor:
  - unauthenticated users, other authenticated users, external services, internal staff roles without need-to-know
- Consent/authorization forms (conceptual, code-visible signals vary):
  - explicit authorization checks (roles/permissions)
  - ownership/relationship checks (user can access only their own data)
  - tenant/project scoping
  - sharing settings / privacy flags / “opt-in” fields
- Key question:
  - does the code ensure the requester is allowed to access *this specific person’s* information?

Where exposure commonly happens (typical sinks / channels)
- API responses and views:
  - JSON/XML/HTML responses that include PII fields
  - server-side templates rendering user profile/contact details
- Data export/list/search endpoints:
  - “list users”, “search”, “export CSV”, “download report”
- Object-by-ID access:
  - fetch profile by userId/accountId provided by requester
- Indirect leaks:
  - returning full objects/entities with PII via default serialization
  - error responses that contain personal details

Typical failure modes (reasoning hints, not assumptions)
- Broken object-level access control (BOLA/IDOR-style privacy leak):
  - user can request another user’s data by changing an identifier
- Over-broad listing:
  - endpoints return too many fields or too many users without filtering by consent/authorization
- Missing field-level protection:
  - authorization allows access to some user info but not sensitive fields; code returns full record anyway
- Confused scope:
  - missing tenant/org scoping; cross-tenant exposure
- Default serialization / DTO mistakes:
  - returning internal entities that include PII fields unintentionally

What “proper prevention” looks like (context-specific)
- Enforce object-level privacy authorization:
  - bind requested user/person record to requester’s identity and relationship (self, admin, caregiver, member, etc.)
- Apply least-PII principle in responses:
  - return only required fields; use DTOs/view models
  - implement field-level filtering based on role/consent (e.g., hide email/phone unless allowed)
- Respect sharing/consent settings:
  - if a record has visibility flags (public/private/friends), enforce them server-side
- Consistent scoping:
  - enforce tenant/org/project scoping for all person data queries

Common weak/insufficient defenses (signals of possible risk)
- Authentication-only gating:
  - “must be logged in” but any logged-in user can access any person’s record
- UI-only privacy:
  - hiding fields in UI but still returning them in API payloads
- Coarse role checks without per-record binding:
  - checking a general role but not whether requester is allowed for the specific target person
- Returning full entities:
  - “User”/“Profile” objects serialized directly with default settings

Evidence to look for in code (static snippet oriented)
- Strong evidence of mitigation:
  - explicit checks that requester is the subject (self) or has a permitted relationship/role for that specific record
  - tenant/org scoping applied to queries and enforced before returning data
  - DTOs that intentionally omit sensitive fields; conditional field inclusion tied to authorization/consent
  - list/search endpoints apply authorization filters and pagination/limits consistent with privacy controls
- Evidence suggesting vulnerability:
  - person/user record fetched by externally supplied ID and returned without object-level authorization
  - list/search/export returns PII fields broadly without evidence of filtering
  - default serialization of person entities that include private fields
  - cross-tenant access paths with no visible scoping

How to use this guideline under incomplete context
- Identify the subject of the data and the requester:
  - whose PII is returned, and who is asking for it?
- Identify the access rule type:
  - self-only, role-based, relationship-based, tenant-based, or consent-based
- Generate a small number of targeted hypotheses:
  - H1: Object-level privacy authorization is missing (ID-based access leak).
  - H2: Field-level filtering is missing (over-sharing of sensitive fields).
  - H3: Tenant/org scoping is missing (cross-scope exposure).
  - H4: Privacy enforcement is implemented in global filters/services/serializers not shown here.
- For each hypothesis, specify:
  (a) evidence in the snippet supporting it (how records are selected and returned),
  (b) evidence needed to confirm it (auth model, consent flags, DTO definitions, serializer config),
  (c) counter-evidence that would refute it (explicit self/relationship checks, scoped queries, field filtering).

Quick red flags in partial code (weak → strong)
- Strong: externally supplied person/user ID used to fetch and return PII without object-level authorization checks.
- Medium: list/search/export endpoints return PII fields for many users without evidence of consent/role-based filtering.
- Medium: direct serialization of user/profile entities with sensitive fields.
- Weak: privacy filtering may occur in helper layers not shown → treat as Unknown and reduce confidence.
"""
if __name__ == "__main__":
    print(CWE_359_RULE)