agents:
- agent_type: conversation
  llm:
    llm_type: deepseek-reasoner
    model: deepseek-reasoner
    model_type: deepseek-reasoner
    temperature: 0.0
  memory:
    memory_type: judge
  name: security_researcher
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - code_author
  - moderator
  - review_board
  role_description: "You are the Security Researcher. Identify all potential security\
    \ vulnerabilities in the given <code> snippet. \nProvide your output as a JSON\
    \ array. Each element in the array represents one identified vulnerability and\
    \ should include:\n- `vulnerability`: A short name or description of the vulnerability.\n\
    - `reason`: A detailed explanation of why this is a vulnerability and how it could\
    \ be exploited.\n- `impact`: The potential consequences if this vulnerability\
    \ were exploited.\n\nNow please analyze the following code.\n\n<code>:\n  void\
    \ operator()(OpKernelContext* ctx, const Tensor& input,\n                  const\
    \ Tensor& filter, int row_stride, int col_stride,\n                  int row_dilation,\
    \ int col_dilation, const Padding& padding,\n                  const std::vector<int64_t>&\
    \ explicit_paddings, Tensor* output,\n                  TensorFormat data_format)\
    \ {\n    DCHECK(data_format == FORMAT_NHWC)\n        << \"Grouped conv implementation\
    \ only \"\n           \"supports NHWC tensor format for now.\";\n\n    const int64_t\
    \ in_depth = input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n\
    \    const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter\
    \ tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3,\
    \ 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle\
    \ = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0),\
    \ tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3)\
    \ / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto\
    \ post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return\
    \ {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2),\
    \ tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\
    \n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]()\
    \ { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary\
    \ tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n\
    \    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T,\
    \ 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary\
    \ tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n\
    \    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T,\
    \ 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion\
    \ of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group\
    \ convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(),\
    \ TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups;\
    \ ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular\
    \ parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async\
    \ Eigen\n      // assignment). This requires small changes to Eigen to support\
    \ async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev):\
    \ Grouped convolution should also support 1x1 filter\n      // optimization.\n\
    \n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice,\
    \ T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n\
    \            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n\
    \            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n\
    \            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n\
    \      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n      \
    \      ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n          \
    \  filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n       \
    \     BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary\
    \ output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1,\
    \ 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device)\
    \ =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: deepseek-reasoner
    model: deepseek-reasoner
    model_type: deepseek-reasoner
    temperature: 0.0
  memory:
    memory_type: judge
  name: code_author
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - security_researcher
  - moderator
  - review_board
  role_description: "You are the Code Author of <code>. The Security Researcher has\
    \ presented a JSON array of alleged vulnerabilities. \nYou must respond as if\
    \ you are presenting your case to a group of decision-makers who will evaluate\
    \ each claim. \nYour tone should be respectful, authoritative, and confident,\
    \ as if you are defending the integrity of your work to a panel of experts.\n\n\
    For each identified vulnerability, produce a corresponding JSON object with the\
    \ following fields:\n- `vulnerability`: The same name/description from the Security\
    \ Researcher\u2019s entry.\n- `response_type`: 'refutation' if you believe this\
    \ concern is unfounded, or 'mitigation' if you acknowledge it and propose a workable\
    \ solution.\n- `reason`: A concise explanation of why the vulnerability is refuted\
    \ or how you propose to mitigate it.\n\n<code>:\n  void operator()(OpKernelContext*\
    \ ctx, const Tensor& input,\n                  const Tensor& filter, int row_stride,\
    \ int col_stride,\n                  int row_dilation, int col_dilation, const\
    \ Padding& padding,\n                  const std::vector<int64_t>& explicit_paddings,\
    \ Tensor* output,\n                  TensorFormat data_format) {\n    DCHECK(data_format\
    \ == FORMAT_NHWC)\n        << \"Grouped conv implementation only \"\n        \
    \   \"supports NHWC tensor format for now.\";\n\n    const int64_t in_depth =\
    \ input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n  \
    \  const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter\
    \ tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3,\
    \ 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle\
    \ = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0),\
    \ tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3)\
    \ / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto\
    \ post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return\
    \ {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2),\
    \ tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\
    \n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]()\
    \ { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary\
    \ tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n\
    \    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T,\
    \ 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary\
    \ tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n\
    \    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T,\
    \ 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion\
    \ of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group\
    \ convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(),\
    \ TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups;\
    \ ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular\
    \ parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async\
    \ Eigen\n      // assignment). This requires small changes to Eigen to support\
    \ async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev):\
    \ Grouped convolution should also support 1x1 filter\n      // optimization.\n\
    \n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice,\
    \ T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n\
    \            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n\
    \            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n\
    \            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n\
    \      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n      \
    \      ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n          \
    \  filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n       \
    \     BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary\
    \ output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1,\
    \ 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device)\
    \ =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: deepseek-reasoner
    model: deepseek-reasoner
    model_type: deepseek-reasoner
    temperature: 0.0
  memory:
    memory_type: judge
  name: moderator
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - review_board
  - security_researcher
  - code_author
  role_description: "You are the Moderator, and your role is to provide a neutral\
    \ summary. \nAfter reviewing both the Security Researcher\u2019s identified vulnerabilities\
    \ and the Code Author\u2019s responses, \nprovide a single JSON object with two\
    \ fields:\n- `researcher_summary`: A concise summary of the vulnerabilities and\
    \ reasoning presented by the Security Researcher.\n- `author_summary`: A concise\
    \ summary of the Code Author\u2019s counterarguments or mitigation strategies.\n\
    \n<code>:\n  void operator()(OpKernelContext* ctx, const Tensor& input,\n    \
    \              const Tensor& filter, int row_stride, int col_stride,\n       \
    \           int row_dilation, int col_dilation, const Padding& padding,\n    \
    \              const std::vector<int64_t>& explicit_paddings, Tensor* output,\n\
    \                  TensorFormat data_format) {\n    DCHECK(data_format == FORMAT_NHWC)\n\
    \        << \"Grouped conv implementation only \"\n           \"supports NHWC\
    \ tensor format for now.\";\n\n    const int64_t in_depth = input.dim_size(3);\n\
    \    const int64_t patch_depth = filter.dim_size(2);\n    const int64_t num_groups\
    \ = in_depth / patch_depth;\n\n    // Shuffle input/filter tensors to have group\
    \ as a leading dimension.\n    std::array<int64_t, 5> shuffle({3, 0, 1, 2, 4});\n\
    \n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle = [&](const Tensor&\
    \ tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0), tensor.dim_size(1),\
    \ tensor.dim_size(2),\n              num_groups, tensor.dim_size(3) / num_groups};\n\
    \    };\n\n    // Compute post shuffle dimemnsions.\n    auto post_shuffle = [&](const\
    \ Tensor& tensor) -> std::array<int64, 5> {\n      return {num_groups, tensor.dim_size(0),\
    \ tensor.dim_size(1),\n              tensor.dim_size(2), tensor.dim_size(3) /\
    \ num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\
    \n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]()\
    \ { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary\
    \ tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n\
    \    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T,\
    \ 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary\
    \ tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n\
    \    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T,\
    \ 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion\
    \ of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group\
    \ convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(),\
    \ TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups;\
    \ ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular\
    \ parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async\
    \ Eigen\n      // assignment). This requires small changes to Eigen to support\
    \ async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev):\
    \ Grouped convolution should also support 1x1 filter\n      // optimization.\n\
    \n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice,\
    \ T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n\
    \            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n\
    \            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n\
    \            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n\
    \      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n      \
    \      ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n          \
    \  filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n       \
    \     BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary\
    \ output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1,\
    \ 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device)\
    \ =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: deepseek-reasoner
    model: deepseek-reasoner
    model_type: deepseek-reasoner
    temperature: 0.0
  memory:
    memory_type: judge
  name: review_board
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver: []
  role_description: "You are the Review Board. After reviewing the Moderator\u2019\
    s summary and <code> (if needed, the original arguments), \nproduce a JSON array\
    \ of verdicts for each vulnerability identified by the Security Researcher. Each\
    \ object in the array should include:\n- `vulnerability`: The same name as given\
    \ by the Security Researcher.\n- `decision`: One of 'valid', 'invalid', or 'partially\
    \ valid'.\n- `severity`: If valid or partially valid, assign a severity ('low',\
    \ 'medium', 'high'); if invalid, use 'none'.\n- `recommended_action`: Suggest\
    \ what should be done next (e.g., 'fix immediately', 'monitor', 'no action needed').\n\
    - `justification`: A brief explanation of why you reached this conclusion, considering\
    \ both the Security Researcher\u2019s and Code Author\u2019s perspectives.\n\n\
    You need to analyze the code and evaluate the reasoning provided by the Security\
    \ Researcher, Code Author, and Moderator. Do not automatically mark a decision\
    \ as 'valid' just because the Code Author refutes it, nor mark it as 'invalid'\
    \ because the Security Researcher claims a vulnerability exists. Instead, carefully\
    \ assess whether their reasoning aligns with the actual security implications\
    \ and technical reality.\n\n<code>:\n  void operator()(OpKernelContext* ctx, const\
    \ Tensor& input,\n                  const Tensor& filter, int row_stride, int\
    \ col_stride,\n                  int row_dilation, int col_dilation, const Padding&\
    \ padding,\n                  const std::vector<int64_t>& explicit_paddings, Tensor*\
    \ output,\n                  TensorFormat data_format) {\n    DCHECK(data_format\
    \ == FORMAT_NHWC)\n        << \"Grouped conv implementation only \"\n        \
    \   \"supports NHWC tensor format for now.\";\n\n    const int64_t in_depth =\
    \ input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n  \
    \  const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter\
    \ tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3,\
    \ 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle\
    \ = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0),\
    \ tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3)\
    \ / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto\
    \ post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return\
    \ {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2),\
    \ tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\
    \n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]()\
    \ { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary\
    \ tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n\
    \    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T,\
    \ 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary\
    \ tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n\
    \    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T,\
    \ 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion\
    \ of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group\
    \ convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(),\
    \ TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups;\
    \ ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular\
    \ parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async\
    \ Eigen\n      // assignment). This requires small changes to Eigen to support\
    \ async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev):\
    \ Grouped convolution should also support 1x1 filter\n      // optimization.\n\
    \n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\
    \n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice,\
    \ T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n\
    \            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n\
    \            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n\
    \            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n\
    \      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n      \
    \      ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n          \
    \  filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n       \
    \     BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary\
    \ output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1,\
    \ 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device)\
    \ =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }"
  verbose: true
environment:
  env_type: judge
  id_save: 195039
  max_turns: 4
  rule:
    describer:
      type: basic
    order:
      type: judge
    selector:
      type: basic
    updater:
      type: basic
    visibility:
      type: all
  target: 1
  task_name: code_vulnerability_review
  unit_tests: None
prompts:
  code_author_role_prompt: "You are the Code Author of <code>. The Security Researcher\
    \ has presented a JSON array of alleged vulnerabilities. \nYou must respond as\
    \ if you are presenting your case to a group of decision-makers who will evaluate\
    \ each claim. \nYour tone should be respectful, authoritative, and confident,\
    \ as if you are defending the integrity of your work to a panel of experts.\n\n\
    For each identified vulnerability, produce a corresponding JSON object with the\
    \ following fields:\n- `vulnerability`: The same name/description from the Security\
    \ Researcher\u2019s entry.\n- `response_type`: 'refutation' if you believe this\
    \ concern is unfounded, or 'mitigation' if you acknowledge it and propose a workable\
    \ solution.\n- `reason`: A concise explanation of why the vulnerability is refuted\
    \ or how you propose to mitigate it."
  moderator_role_prompt: "You are the Moderator, and your role is to provide a neutral\
    \ summary. \nAfter reviewing both the Security Researcher\u2019s identified vulnerabilities\
    \ and the Code Author\u2019s responses, \nprovide a single JSON object with two\
    \ fields:\n- `researcher_summary`: A concise summary of the vulnerabilities and\
    \ reasoning presented by the Security Researcher.\n- `author_summary`: A concise\
    \ summary of the Code Author\u2019s counterarguments or mitigation strategies."
  prompt: 'You are working in a programming team to check whether a code have a potential
    vulnerability in it.


    ${role_description}


    ${chat_history}'
  review_board_role_prompt: "You are the Review Board. After reviewing the Moderator\u2019\
    s summary and <code> (if needed, the original arguments), \nproduce a JSON array\
    \ of verdicts for each vulnerability identified by the Security Researcher. Each\
    \ object in the array should include:\n- `vulnerability`: The same name as given\
    \ by the Security Researcher.\n- `decision`: One of 'valid', 'invalid', or 'partially\
    \ valid'.\n- `severity`: If valid or partially valid, assign a severity ('low',\
    \ 'medium', 'high'); if invalid, use 'none'.\n- `recommended_action`: Suggest\
    \ what should be done next (e.g., 'fix immediately', 'monitor', 'no action needed').\n\
    - `justification`: A brief explanation of why you reached this conclusion, considering\
    \ both the Security Researcher\u2019s and Code Author\u2019s perspectives.\n\n\
    You need to analyze the code and evaluate the reasoning provided by the Security\
    \ Researcher, Code Author, and Moderator. Do not automatically mark a decision\
    \ as 'valid' just because the Code Author refutes it, nor mark it as 'invalid'\
    \ because the Security Researcher claims a vulnerability exists. Instead, carefully\
    \ assess whether their reasoning aligns with the actual security implications\
    \ and technical reality."
  security_researcher_role_prompt: "You are the Security Researcher. Identify all\
    \ potential security vulnerabilities in the given <code> snippet. \nProvide your\
    \ output as a JSON array. Each element in the array represents one identified\
    \ vulnerability and should include:\n- `vulnerability`: A short name or description\
    \ of the vulnerability.\n- `reason`: A detailed explanation of why this is a vulnerability\
    \ and how it could be exploited.\n- `impact`: The potential consequences if this\
    \ vulnerability were exploited.\n\nNow please analyze the following code."
