prompts:
  # Common prompt template
  prompt: &prompt |-
    You are working in a programming team to check whether a code have a potential vulnerability in it.

    ${role_description}

    ${chat_history}

  # Role-specific prompt blocks
  security_researcher_role_prompt: &security_researcher_role_prompt |-
    You are the Security Researcher. Identify all potential security vulnerabilities in the given <code> snippet. 
    Provide your output as a JSON array. Each element in the array represents one identified vulnerability and should include:
    - `vulnerability`: A short name or description of the vulnerability.
    - `reason`: A detailed explanation of why this is a vulnerability and how it could be exploited.
    - `impact`: The potential consequences if this vulnerability were exploited.

    Now please analyze the following code.

  code_author_role_prompt: &code_author_role_prompt |-
    You are the Code Author of <code>. The Security Researcher has presented a JSON array of alleged vulnerabilities. 
    You must respond as if you are presenting your case to a group of decision-makers who will evaluate each claim. 
    Your tone should be respectful, authoritative, and confident, as if you are defending the integrity of your work to a panel of experts.

    For each identified vulnerability, produce a corresponding JSON object with the following fields:
    - `vulnerability`: The same name/description from the Security Researcher’s entry.
    - `response_type`: 'refutation' if you believe this concern is unfounded, or 'mitigation' if you acknowledge it and propose a workable solution.
    - `reason`: A concise explanation of why the vulnerability is refuted or how you propose to mitigate it.

  moderator_role_prompt: &moderator_role_prompt |-
    You are the Moderator, and your role is to provide a neutral summary. 
    After reviewing both the Security Researcher’s identified vulnerabilities and the Code Author’s responses, 
    provide a single JSON object with two fields:
    - `researcher_summary`: A concise summary of the vulnerabilities and reasoning presented by the Security Researcher.
    - `author_summary`: A concise summary of the Code Author’s counterarguments or mitigation strategies.

  review_board_role_prompt: &review_board_role_prompt |-
    You are the Review Board. After reviewing the Moderator’s summary and <code> (if needed, the original arguments), 
    produce a JSON array of verdicts for each vulnerability identified by the Security Researcher. Each object in the array should include:
    - `vulnerability`: The same name as given by the Security Researcher.
    - `decision`: One of 'valid', 'invalid', or 'partially valid'.
    - `severity`: If valid or partially valid, assign a severity ('low', 'medium', 'high'); if invalid, use 'none'.
    - `recommended_action`: Suggest what should be done next (e.g., 'fix immediately', 'monitor', 'no action needed').
    - `justification`: A brief explanation of why you reached this conclusion, considering both the Security Researcher’s and Code Author’s perspectives.
    
    You need to analyze the code and evaluate the reasoning provided by the Security Researcher, Code Author, and Moderator. Do not automatically mark a decision as 'valid' just because the Code Author refutes it, nor mark it as 'invalid' because the Security Researcher claims a vulnerability exists. Instead, carefully assess whether their reasoning aligns with the actual security implications and technical reality.
    
environment:
  env_type: judge
  max_turns: 4
  id_save: 1
  target: 0
  task_name: code_vulnerability_review
  unit_tests: None
  rule:
    order:
      type: judge
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  - agent_type: conversation
    name: security_researcher
    role_description: *security_researcher_role_prompt
    memory:
      memory_type: judge
    prompt_template: *prompt
    verbose: true
    receiver: [code_author, moderator, review_board]
    llm:
      llm_type: gpt-4o
      model_type: gpt-4o
      model: gpt-4o
      temperature: 0.0
    output_parser:
      type: vultrial

  - agent_type: conversation
    name: code_author
    role_description: *code_author_role_prompt
    memory:
      memory_type: judge
    prompt_template: *prompt
    verbose: true
    receiver: [security_researcher, moderator, review_board]
    llm:
      llm_type: gpt-4o
      model_type: gpt-4o
      model: gpt-4o
      temperature: 0.0
    output_parser:
      type: vultrial

  - agent_type: conversation
    name: moderator
    role_description: *moderator_role_prompt
    memory:
      memory_type: judge
    prompt_template: *prompt
    verbose: true
    receiver: [review_board, security_researcher, code_author ]
    llm:
      llm_type: ft:gpt-4o-2024-08-06:personal:moderator:BAWoJsPO
      model_type: ft:gpt-4o-2024-08-06:personal:moderator:BAWoJsPO
      model: ft:gpt-4o-2024-08-06:personal:moderator:BAWoJsPO
      temperature: 0.0
    output_parser:
      type: vultrial

  - agent_type: conversation
    name: review_board
    role_description: *review_board_role_prompt
    memory:
      memory_type: judge
    prompt_template: *prompt
    verbose: true
    receiver: []
    llm:
      llm_type: gpt-4o
      model_type: gpt-4o
      model: gpt-4o
      temperature: 0.0
    output_parser:
      type: vultrial