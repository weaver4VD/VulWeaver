agents:
- agent_type: conversation
  llm:
    llm_type: gpt-3.5-turbo
    model: gpt-3.5-turbo
    model_type: gpt-3.5-turbo
    temperature: 0.0
  memory:
    memory_type: judge
  name: security_researcher
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - code_author
  - moderator
  - review_board
  role_description: "You are the Security Researcher. Identify all potential security\
    \ vulnerabilities in the given <code> snippet. \nProvide your output as a JSON\
    \ array. Each element in the array represents one identified vulnerability and\
    \ should include:\n- `vulnerability`: A short name or description of the vulnerability.\n\
    - `reason`: A detailed explanation of why this is a vulnerability and how it could\
    \ be exploited.\n- `impact`: The potential consequences if this vulnerability\
    \ were exploited.\n\nNow please analyze the following code.\n\n<code>:\n  void\
    \ Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input\
    \ = ctx->input(kInputTensorIndex);\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n\
    \      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const\
    \ void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec\
    \ = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n\
    \          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n\
    \      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n\
    \      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\
    \      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n\
    \      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\
    \n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n    \
    \      ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel\
    \ operator\"\n                                  \"supports 4D tensors only.\"\
    ));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n\
    \          errors::InvalidArgument(\"input_min has incorrect size, expected \"\
    ,\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n\
    \      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n    \
    \      errors::InvalidArgument(\"input_max has incorrect size, expected \",\n\
    \                                  depth, \" was \", input_max_vec.dim_size(0)));\n\
    \n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\
    \n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n    \
    \  const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n\
    \                   std::abs(input_requested_max_float));\n      Tensor* output\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n\
    \                                               input.shape(), &output));\n\n\
    \      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i)\
    \ {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n\
    \                                          std::abs(input_max_vec_data[i]));\n\
    \        scales[i] = factor * (min_max_from_vec / requested_min_max /\n      \
    \                        static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr\
    \ reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims\
    \ dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n\
    \      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n\
    \                                           memory::format_tag::nhwc);\n     \
    \ memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ?\
    \ memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                        \
    \     memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order,\
    \ MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\
    \n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n\
    \      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf\
    \ = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n\
    \      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n\
    \      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md,\
    \ cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n\
    \          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc\
    \ reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n\
    \                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream>\
    \ reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp,\
    \ cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args =\
    \ {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO,\
    \ *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n\
    \          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream,\
    \ reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex,\
    \ {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex,\
    \ {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n\
    \      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch\
    \ (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status)\
    \ +\n                         \", message: \" + std::string(e.message) + \", in\
    \ file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n\
    \      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an\
    \ exception:\", error_msg));\n    }\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: gpt-3.5-turbo
    model: gpt-3.5-turbo
    model_type: gpt-3.5-turbo
    temperature: 0.0
  memory:
    memory_type: judge
  name: code_author
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - security_researcher
  - moderator
  - review_board
  role_description: "You are the Code Author of <code>. The Security Researcher has\
    \ presented a JSON array of alleged vulnerabilities. \nYou must respond as if\
    \ you are presenting your case to a group of decision-makers who will evaluate\
    \ each claim. \nYour tone should be respectful, authoritative, and confident,\
    \ as if you are defending the integrity of your work to a panel of experts.\n\n\
    For each identified vulnerability, produce a corresponding JSON object with the\
    \ following fields:\n- `vulnerability`: The same name/description from the Security\
    \ Researcher\xE2\u20AC\u2122s entry.\n- `response_type`: 'refutation' if you believe\
    \ this concern is unfounded, or 'mitigation' if you acknowledge it and propose\
    \ a workable solution.\n- `reason`: A concise explanation of why the vulnerability\
    \ is refuted or how you propose to mitigate it.\n\n<code>:\n  void Compute(OpKernelContext*\
    \ ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n\
    \      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float*\
    \ input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const\
    \ void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec\
    \ = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n\
    \          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n\
    \      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n\
    \      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\
    \      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n\
    \      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\
    \n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n    \
    \      ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel\
    \ operator\"\n                                  \"supports 4D tensors only.\"\
    ));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n\
    \          errors::InvalidArgument(\"input_min has incorrect size, expected \"\
    ,\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n\
    \      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n    \
    \      errors::InvalidArgument(\"input_max has incorrect size, expected \",\n\
    \                                  depth, \" was \", input_max_vec.dim_size(0)));\n\
    \n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\
    \n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n    \
    \  const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n\
    \                   std::abs(input_requested_max_float));\n      Tensor* output\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n\
    \                                               input.shape(), &output));\n\n\
    \      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i)\
    \ {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n\
    \                                          std::abs(input_max_vec_data[i]));\n\
    \        scales[i] = factor * (min_max_from_vec / requested_min_max /\n      \
    \                        static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr\
    \ reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims\
    \ dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n\
    \      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n\
    \                                           memory::format_tag::nhwc);\n     \
    \ memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ?\
    \ memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                        \
    \     memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order,\
    \ MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\
    \n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n\
    \      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf\
    \ = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n\
    \      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n\
    \      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md,\
    \ cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n\
    \          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc\
    \ reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n\
    \                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream>\
    \ reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp,\
    \ cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args =\
    \ {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO,\
    \ *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n\
    \          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream,\
    \ reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex,\
    \ {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex,\
    \ {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n\
    \      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch\
    \ (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status)\
    \ +\n                         \", message: \" + std::string(e.message) + \", in\
    \ file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n\
    \      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an\
    \ exception:\", error_msg));\n    }\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: gpt-3.5-turbo
    model: gpt-3.5-turbo
    model_type: gpt-3.5-turbo
    temperature: 0.0
  memory:
    memory_type: judge
  name: moderator
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - review_board
  - security_researcher
  - code_author
  role_description: "You are the Moderator, and your role is to provide a neutral\
    \ summary. \nAfter reviewing both the Security Researcher\xE2\u20AC\u2122s identified\
    \ vulnerabilities and the Code Author\xE2\u20AC\u2122s responses, \nprovide a\
    \ single JSON object with two fields:\n- `researcher_summary`: A concise summary\
    \ of the vulnerabilities and reasoning presented by the Security Researcher.\n\
    - `author_summary`: A concise summary of the Code Author\xE2\u20AC\u2122s counterarguments\
    \ or mitigation strategies.\n\n<code>:\n  void Compute(OpKernelContext* ctx) override\
    \ {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n \
    \     const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float*\
    \ input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const\
    \ void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec\
    \ = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n\
    \          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n\
    \      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n\
    \      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\
    \      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n\
    \      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\
    \n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n    \
    \      ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel\
    \ operator\"\n                                  \"supports 4D tensors only.\"\
    ));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n\
    \          errors::InvalidArgument(\"input_min has incorrect size, expected \"\
    ,\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n\
    \      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n    \
    \      errors::InvalidArgument(\"input_max has incorrect size, expected \",\n\
    \                                  depth, \" was \", input_max_vec.dim_size(0)));\n\
    \n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\
    \n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n    \
    \  const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n\
    \                   std::abs(input_requested_max_float));\n      Tensor* output\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n\
    \                                               input.shape(), &output));\n\n\
    \      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i)\
    \ {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n\
    \                                          std::abs(input_max_vec_data[i]));\n\
    \        scales[i] = factor * (min_max_from_vec / requested_min_max /\n      \
    \                        static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr\
    \ reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims\
    \ dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n\
    \      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n\
    \                                           memory::format_tag::nhwc);\n     \
    \ memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ?\
    \ memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                        \
    \     memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order,\
    \ MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\
    \n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n\
    \      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf\
    \ = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n\
    \      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n\
    \      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md,\
    \ cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n\
    \          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc\
    \ reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n\
    \                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream>\
    \ reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp,\
    \ cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args =\
    \ {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO,\
    \ *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n\
    \          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream,\
    \ reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex,\
    \ {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex,\
    \ {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n\
    \      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch\
    \ (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status)\
    \ +\n                         \", message: \" + std::string(e.message) + \", in\
    \ file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n\
    \      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an\
    \ exception:\", error_msg));\n    }\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: gpt-3.5-turbo
    model: gpt-3.5-turbo
    model_type: gpt-3.5-turbo
    temperature: 0.0
  memory:
    memory_type: judge
  name: review_board
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver: []
  role_description: "You are the Review Board. After reviewing the Moderator\xE2\u20AC\
    \u2122s summary and <code> (if needed, the original arguments), \nproduce a JSON\
    \ array of verdicts for each vulnerability identified by the Security Researcher.\
    \ Each object in the array should include:\n- `vulnerability`: The same name as\
    \ given by the Security Researcher.\n- `decision`: One of 'valid', 'invalid',\
    \ or 'partially valid'.\n- `severity`: If valid or partially valid, assign a severity\
    \ ('low', 'medium', 'high'); if invalid, use 'none'.\n- `recommended_action`:\
    \ Suggest what should be done next (e.g., 'fix immediately', 'monitor', 'no action\
    \ needed').\n- `justification`: A brief explanation of why you reached this conclusion,\
    \ considering both the Security Researcher\xE2\u20AC\u2122s and Code Author\xE2\
    \u20AC\u2122s perspectives.\n\nYou need to analyze the code and evaluate the reasoning\
    \ provided by the Security Researcher, Code Author, and Moderator. Do not automatically\
    \ mark a decision as 'valid' just because the Code Author refutes it, nor mark\
    \ it as 'invalid' because the Security Researcher claims a vulnerability exists.\
    \ Instead, carefully assess whether their reasoning aligns with the actual security\
    \ implications and technical reality.\n\n<code>:\n  void Compute(OpKernelContext*\
    \ ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n\
    \      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float*\
    \ input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const\
    \ void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec\
    \ = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n\
    \          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n\
    \      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n\
    \      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\
    \      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n\
    \      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\
    \n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n    \
    \      ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel\
    \ operator\"\n                                  \"supports 4D tensors only.\"\
    ));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n\
    \          errors::InvalidArgument(\"input_min has incorrect size, expected \"\
    ,\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n\
    \      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n    \
    \      errors::InvalidArgument(\"input_max has incorrect size, expected \",\n\
    \                                  depth, \" was \", input_max_vec.dim_size(0)));\n\
    \n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\
    \n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n    \
    \  const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n\
    \                   std::abs(input_requested_max_float));\n      Tensor* output\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n\
    \                                               input.shape(), &output));\n\n\
    \      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i)\
    \ {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n\
    \                                          std::abs(input_max_vec_data[i]));\n\
    \        scales[i] = factor * (min_max_from_vec / requested_min_max /\n      \
    \                        static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr\
    \ reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims\
    \ dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n\
    \      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n\
    \                                           memory::format_tag::nhwc);\n     \
    \ memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ?\
    \ memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                        \
    \     memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order,\
    \ MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\
    \n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n\
    \      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf\
    \ = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n\
    \      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n\
    \      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md,\
    \ cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n\
    \          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc\
    \ reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n\
    \                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream>\
    \ reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp,\
    \ cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args =\
    \ {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO,\
    \ *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n\
    \          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream,\
    \ reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max\
    \ = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex,\
    \ {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex,\
    \ {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n\
    \      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch\
    \ (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status)\
    \ +\n                         \", message: \" + std::string(e.message) + \", in\
    \ file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n\
    \      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an\
    \ exception:\", error_msg));\n    }\n  }"
  verbose: true
environment:
  env_type: judge
  id_save: 197239
  max_turns: 4
  rule:
    describer:
      type: basic
    order:
      type: judge
    selector:
      type: basic
    updater:
      type: basic
    visibility:
      type: all
  target: 1
  task_name: code_vulnerability_review
  unit_tests: None
prompts:
  code_author_role_prompt: "You are the Code Author of <code>. The Security Researcher\
    \ has presented a JSON array of alleged vulnerabilities. \nYou must respond as\
    \ if you are presenting your case to a group of decision-makers who will evaluate\
    \ each claim. \nYour tone should be respectful, authoritative, and confident,\
    \ as if you are defending the integrity of your work to a panel of experts.\n\n\
    For each identified vulnerability, produce a corresponding JSON object with the\
    \ following fields:\n- `vulnerability`: The same name/description from the Security\
    \ Researcher\xE2\u20AC\u2122s entry.\n- `response_type`: 'refutation' if you believe\
    \ this concern is unfounded, or 'mitigation' if you acknowledge it and propose\
    \ a workable solution.\n- `reason`: A concise explanation of why the vulnerability\
    \ is refuted or how you propose to mitigate it."
  moderator_role_prompt: "You are the Moderator, and your role is to provide a neutral\
    \ summary. \nAfter reviewing both the Security Researcher\xE2\u20AC\u2122s identified\
    \ vulnerabilities and the Code Author\xE2\u20AC\u2122s responses, \nprovide a\
    \ single JSON object with two fields:\n- `researcher_summary`: A concise summary\
    \ of the vulnerabilities and reasoning presented by the Security Researcher.\n\
    - `author_summary`: A concise summary of the Code Author\xE2\u20AC\u2122s counterarguments\
    \ or mitigation strategies."
  prompt: 'You are working in a programming team to check whether a code have a potential
    vulnerability in it.


    ${role_description}


    ${chat_history}'
  review_board_role_prompt: "You are the Review Board. After reviewing the Moderator\xE2\
    \u20AC\u2122s summary and <code> (if needed, the original arguments), \nproduce\
    \ a JSON array of verdicts for each vulnerability identified by the Security Researcher.\
    \ Each object in the array should include:\n- `vulnerability`: The same name as\
    \ given by the Security Researcher.\n- `decision`: One of 'valid', 'invalid',\
    \ or 'partially valid'.\n- `severity`: If valid or partially valid, assign a severity\
    \ ('low', 'medium', 'high'); if invalid, use 'none'.\n- `recommended_action`:\
    \ Suggest what should be done next (e.g., 'fix immediately', 'monitor', 'no action\
    \ needed').\n- `justification`: A brief explanation of why you reached this conclusion,\
    \ considering both the Security Researcher\xE2\u20AC\u2122s and Code Author\xE2\
    \u20AC\u2122s perspectives.\n\nYou need to analyze the code and evaluate the reasoning\
    \ provided by the Security Researcher, Code Author, and Moderator. Do not automatically\
    \ mark a decision as 'valid' just because the Code Author refutes it, nor mark\
    \ it as 'invalid' because the Security Researcher claims a vulnerability exists.\
    \ Instead, carefully assess whether their reasoning aligns with the actual security\
    \ implications and technical reality."
  security_researcher_role_prompt: "You are the Security Researcher. Identify all\
    \ potential security vulnerabilities in the given <code> snippet. \nProvide your\
    \ output as a JSON array. Each element in the array represents one identified\
    \ vulnerability and should include:\n- `vulnerability`: A short name or description\
    \ of the vulnerability.\n- `reason`: A detailed explanation of why this is a vulnerability\
    \ and how it could be exploited.\n- `impact`: The potential consequences if this\
    \ vulnerability were exploited.\n\nNow please analyze the following code."
