agents:
- agent_type: conversation
  llm:
    llm_type: gpt-4o
    model: gpt-4o
    model_type: gpt-4o
    temperature: 0.0
  memory:
    memory_type: judge
  name: security_researcher
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - code_author
  - moderator
  - review_board
  role_description: "You are the Security Researcher. Identify all potential security\
    \ vulnerabilities in the given <code> snippet. \nProvide your output as a JSON\
    \ array. Each element in the array represents one identified vulnerability and\
    \ should include:\n- `vulnerability`: A short name or description of the vulnerability.\n\
    - `reason`: A detailed explanation of why this is a vulnerability and how it could\
    \ be exploited.\n- `impact`: The potential consequences if this vulnerability\
    \ were exploited.\n\nNow please analyze the following code.\n\n<code>:\n  void\
    \ Compute(OpKernelContext* context) override {\n    // Read ragged_splits inputs.\n\
    \    OpInputList ragged_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"\
    rt_nested_splits\",\n                                                &ragged_nested_splits_in));\n\
    \    const int ragged_nested_splits_len = ragged_nested_splits_in.size();\n  \
    \  RaggedTensorVariant batched_ragged_input;\n    // Read ragged_values input.\n\
    \    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n\
    \    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n\
    \    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n\
    \    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n\
    \      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0,\
    \ TensorShape({}),\n                                                       &encoded_scalar));\n\
    \      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n\
    \      return;\n    }\n\n    // Checked here instead of at input in case batched_input_\
    \ is false\n    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n         \
    \       errors::InvalidArgument(\n                    \"rt_nested_splits must\
    \ be a list of one or more, but \"\n                    \"received rt_nested_splits\
    \ of length 0.\"));\n\n    // Unbatch the Ragged Tensor and encode the components.\n\
    \    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec\
    \ =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components\
    \ = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components\
    \ >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n   \
    \ OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n  \
    \                              batched_ragged_input, &unbatched_ragged_input));\n\
    \n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n\
    \    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n\
    \    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n\
    \                                            &encoded_vector));\n    auto encoded_vector_t\
    \ = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++)\
    \ {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: gpt-4o
    model: gpt-4o
    model_type: gpt-4o
    temperature: 0.0
  memory:
    memory_type: judge
  name: code_author
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - security_researcher
  - moderator
  - review_board
  role_description: "You are the Code Author of <code>. The Security Researcher has\
    \ presented a JSON array of alleged vulnerabilities. \nYou must respond as if\
    \ you are presenting your case to a group of decision-makers who will evaluate\
    \ each claim. \nYour tone should be respectful, authoritative, and confident,\
    \ as if you are defending the integrity of your work to a panel of experts.\n\n\
    For each identified vulnerability, produce a corresponding JSON object with the\
    \ following fields:\n- `vulnerability`: The same name/description from the Security\
    \ Researcher\xE2\u20AC\u2122s entry.\n- `response_type`: 'refutation' if you believe\
    \ this concern is unfounded, or 'mitigation' if you acknowledge it and propose\
    \ a workable solution.\n- `reason`: A concise explanation of why the vulnerability\
    \ is refuted or how you propose to mitigate it.\n\n<code>:\n  void Compute(OpKernelContext*\
    \ context) override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n\
    \    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n     \
    \                                           &ragged_nested_splits_in));\n    const\
    \ int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant\
    \ batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n\
    \    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n\
    \    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n\
    \    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n\
    \      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0,\
    \ TensorShape({}),\n                                                       &encoded_scalar));\n\
    \      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n\
    \      return;\n    }\n\n    // Checked here instead of at input in case batched_input_\
    \ is false\n    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n         \
    \       errors::InvalidArgument(\n                    \"rt_nested_splits must\
    \ be a list of one or more, but \"\n                    \"received rt_nested_splits\
    \ of length 0.\"));\n\n    // Unbatch the Ragged Tensor and encode the components.\n\
    \    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec\
    \ =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components\
    \ = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components\
    \ >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n   \
    \ OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n  \
    \                              batched_ragged_input, &unbatched_ragged_input));\n\
    \n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n\
    \    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n\
    \    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n\
    \                                            &encoded_vector));\n    auto encoded_vector_t\
    \ = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++)\
    \ {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: ft:gpt-4o-2024-08-06:personal:moderator:BAWoJsPO
    model: ft:gpt-4o-2024-08-06:personal:moderator:BAWoJsPO
    model_type: ft:gpt-4o-2024-08-06:personal:moderator:BAWoJsPO
    temperature: 0.0
  memory:
    memory_type: judge
  name: moderator
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver:
  - review_board
  - security_researcher
  - code_author
  role_description: "You are the Moderator, and your role is to provide a neutral\
    \ summary. \nAfter reviewing both the Security Researcher\xE2\u20AC\u2122s identified\
    \ vulnerabilities and the Code Author\xE2\u20AC\u2122s responses, \nprovide a\
    \ single JSON object with two fields:\n- `researcher_summary`: A concise summary\
    \ of the vulnerabilities and reasoning presented by the Security Researcher.\n\
    - `author_summary`: A concise summary of the Code Author\xE2\u20AC\u2122s counterarguments\
    \ or mitigation strategies.\n\n<code>:\n  void Compute(OpKernelContext* context)\
    \ override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n\
    \    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n     \
    \                                           &ragged_nested_splits_in));\n    const\
    \ int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant\
    \ batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n\
    \    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n\
    \    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n\
    \    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n\
    \      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0,\
    \ TensorShape({}),\n                                                       &encoded_scalar));\n\
    \      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n\
    \      return;\n    }\n\n    // Checked here instead of at input in case batched_input_\
    \ is false\n    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n         \
    \       errors::InvalidArgument(\n                    \"rt_nested_splits must\
    \ be a list of one or more, but \"\n                    \"received rt_nested_splits\
    \ of length 0.\"));\n\n    // Unbatch the Ragged Tensor and encode the components.\n\
    \    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec\
    \ =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components\
    \ = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components\
    \ >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n   \
    \ OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n  \
    \                              batched_ragged_input, &unbatched_ragged_input));\n\
    \n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n\
    \    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n\
    \    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n\
    \                                            &encoded_vector));\n    auto encoded_vector_t\
    \ = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++)\
    \ {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }"
  verbose: true
- agent_type: conversation
  llm:
    llm_type: gpt-4o
    model: gpt-4o
    model_type: gpt-4o
    temperature: 0.0
  memory:
    memory_type: judge
  name: review_board
  output_parser:
    type: vultrial
  prompt_template: 'You are working in a programming team to check whether a code
    have a potential vulnerability in it.


    ${role_description}


    ${chat_history}'
  receiver: []
  role_description: "You are the Review Board. After reviewing the Moderator\xE2\u20AC\
    \u2122s summary and <code> (if needed, the original arguments), \nproduce a JSON\
    \ array of verdicts for each vulnerability identified by the Security Researcher.\
    \ Each object in the array should include:\n- `vulnerability`: The same name as\
    \ given by the Security Researcher.\n- `decision`: One of 'valid', 'invalid',\
    \ or 'partially valid'.\n- `severity`: If valid or partially valid, assign a severity\
    \ ('low', 'medium', 'high'); if invalid, use 'none'.\n- `recommended_action`:\
    \ Suggest what should be done next (e.g., 'fix immediately', 'monitor', 'no action\
    \ needed').\n- `justification`: A brief explanation of why you reached this conclusion,\
    \ considering both the Security Researcher\xE2\u20AC\u2122s and Code Author\xE2\
    \u20AC\u2122s perspectives.\n\nYou need to analyze the code and evaluate the reasoning\
    \ provided by the Security Researcher, Code Author, and Moderator. Do not automatically\
    \ mark a decision as 'valid' just because the Code Author refutes it, nor mark\
    \ it as 'invalid' because the Security Researcher claims a vulnerability exists.\
    \ Instead, carefully assess whether their reasoning aligns with the actual security\
    \ implications and technical reality.\n\n<code>:\n  void Compute(OpKernelContext*\
    \ context) override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n\
    \    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n     \
    \                                           &ragged_nested_splits_in));\n    const\
    \ int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant\
    \ batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n\
    \    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n\
    \    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n\
    \    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n\
    \      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0,\
    \ TensorShape({}),\n                                                       &encoded_scalar));\n\
    \      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n\
    \      return;\n    }\n\n    // Checked here instead of at input in case batched_input_\
    \ is false\n    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n         \
    \       errors::InvalidArgument(\n                    \"rt_nested_splits must\
    \ be a list of one or more, but \"\n                    \"received rt_nested_splits\
    \ of length 0.\"));\n\n    // Unbatch the Ragged Tensor and encode the components.\n\
    \    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec\
    \ =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components\
    \ = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components\
    \ >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n   \
    \ OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n  \
    \                              batched_ragged_input, &unbatched_ragged_input));\n\
    \n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n\
    \    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n\
    \    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n\
    \                                            &encoded_vector));\n    auto encoded_vector_t\
    \ = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++)\
    \ {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }"
  verbose: true
environment:
  env_type: judge
  id_save: 262803
  max_turns: 4
  rule:
    describer:
      type: basic
    order:
      type: judge
    selector:
      type: basic
    updater:
      type: basic
    visibility:
      type: all
  target: 0
  task_name: code_vulnerability_review
  unit_tests: None
prompts:
  code_author_role_prompt: "You are the Code Author of <code>. The Security Researcher\
    \ has presented a JSON array of alleged vulnerabilities. \nYou must respond as\
    \ if you are presenting your case to a group of decision-makers who will evaluate\
    \ each claim. \nYour tone should be respectful, authoritative, and confident,\
    \ as if you are defending the integrity of your work to a panel of experts.\n\n\
    For each identified vulnerability, produce a corresponding JSON object with the\
    \ following fields:\n- `vulnerability`: The same name/description from the Security\
    \ Researcher\xE2\u20AC\u2122s entry.\n- `response_type`: 'refutation' if you believe\
    \ this concern is unfounded, or 'mitigation' if you acknowledge it and propose\
    \ a workable solution.\n- `reason`: A concise explanation of why the vulnerability\
    \ is refuted or how you propose to mitigate it."
  moderator_role_prompt: "You are the Moderator, and your role is to provide a neutral\
    \ summary. \nAfter reviewing both the Security Researcher\xE2\u20AC\u2122s identified\
    \ vulnerabilities and the Code Author\xE2\u20AC\u2122s responses, \nprovide a\
    \ single JSON object with two fields:\n- `researcher_summary`: A concise summary\
    \ of the vulnerabilities and reasoning presented by the Security Researcher.\n\
    - `author_summary`: A concise summary of the Code Author\xE2\u20AC\u2122s counterarguments\
    \ or mitigation strategies."
  prompt: 'You are working in a programming team to check whether a code have a potential
    vulnerability in it.


    ${role_description}


    ${chat_history}'
  review_board_role_prompt: "You are the Review Board. After reviewing the Moderator\xE2\
    \u20AC\u2122s summary and <code> (if needed, the original arguments), \nproduce\
    \ a JSON array of verdicts for each vulnerability identified by the Security Researcher.\
    \ Each object in the array should include:\n- `vulnerability`: The same name as\
    \ given by the Security Researcher.\n- `decision`: One of 'valid', 'invalid',\
    \ or 'partially valid'.\n- `severity`: If valid or partially valid, assign a severity\
    \ ('low', 'medium', 'high'); if invalid, use 'none'.\n- `recommended_action`:\
    \ Suggest what should be done next (e.g., 'fix immediately', 'monitor', 'no action\
    \ needed').\n- `justification`: A brief explanation of why you reached this conclusion,\
    \ considering both the Security Researcher\xE2\u20AC\u2122s and Code Author\xE2\
    \u20AC\u2122s perspectives.\n\nYou need to analyze the code and evaluate the reasoning\
    \ provided by the Security Researcher, Code Author, and Moderator. Do not automatically\
    \ mark a decision as 'valid' just because the Code Author refutes it, nor mark\
    \ it as 'invalid' because the Security Researcher claims a vulnerability exists.\
    \ Instead, carefully assess whether their reasoning aligns with the actual security\
    \ implications and technical reality."
  security_researcher_role_prompt: "You are the Security Researcher. Identify all\
    \ potential security vulnerabilities in the given <code> snippet. \nProvide your\
    \ output as a JSON array. Each element in the array represents one identified\
    \ vulnerability and should include:\n- `vulnerability`: A short name or description\
    \ of the vulnerability.\n- `reason`: A detailed explanation of why this is a vulnerability\
    \ and how it could be exploited.\n- `impact`: The potential consequences if this\
    \ vulnerability were exploited.\n\nNow please analyze the following code."
