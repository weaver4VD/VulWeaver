[
    {
        "function_name": "iwl_trans_pcie_alloc",
        "vulnerability": "Null Pointer Dereference",
        "criticism": "The reasoning correctly identifies a potential null pointer dereference if `pcim_iomap_table(pdev)` returns NULL. However, the code does check `trans_pcie->hw_base` immediately after assignment, which mitigates the risk of dereferencing a null pointer at that point. The vulnerability is valid but the reasoning overstates the risk since the check is in place. The severity is moderate as it could lead to a crash, but the profitability is low as it doesn't lead to a security breach.",
        "correctness": 7,
        "severity": 5,
        "profitability": 2,
        "reason": "If the `pcim_iomap_regions_request_all` function fails, it is logged and the function jumps to `out_no_pci`. However, the code attempts to access `pcim_iomap_table(pdev)[0]` without checking if `pcim_iomap_regions_request_all` was successful. This could lead to a null pointer dereference if `pcim_iomap_table(pdev)` returns NULL.",
        "code": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\ttrans_pcie->def_rx_queue = 0;\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\tpci_set_master(pdev);\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t}\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\treturn trans;\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "file_name": "209955.sol"
    },
    {
        "function_name": "iwl_trans_pcie_alloc",
        "vulnerability": "Insecure DMA Configuration",
        "criticism": "The reasoning highlights a potential issue with falling back to a 32-bit DMA mask, which could allow less restricted devices to perform DMA. However, the code does handle the failure of setting a 64-bit mask by logging an error and exiting if a suitable DMA mask cannot be set. The vulnerability is valid but the reasoning doesn't fully acknowledge the error handling in place. The severity is moderate due to potential unauthorized access, but the profitability is low as it requires specific conditions to exploit.",
        "correctness": 6,
        "severity": 5,
        "profitability": 3,
        "reason": "This code sets the DMA mask based on the `addr_size` determined earlier. If the initial attempt to set DMA mask fails, it falls back to a 32-bit mask. This could potentially allow a device with fewer restrictions to perform DMA, leading to unauthorized memory access if not properly secured.",
        "code": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\ttrans_pcie->def_rx_queue = 0;\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\tpci_set_master(pdev);\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t}\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\treturn trans;\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "file_name": "209955.sol"
    },
    {
        "function_name": "iwl_trans_pcie_alloc",
        "vulnerability": "Potential Buffer Overflow",
        "criticism": "The reasoning suggests a potential buffer overflow with `snprintf`, but `snprintf` is designed to prevent overflows by limiting the number of characters written. The buffer size is likely sufficient for the formatted string, given the typical size of PCI IDs. The vulnerability is unlikely, and the reasoning overstates the risk. The severity and profitability are both low as the risk of overflow is minimal.",
        "correctness": 3,
        "severity": 2,
        "profitability": 1,
        "reason": "The use of `snprintf` with `sizeof(trans->hw_id_str)` assumes that the buffer size is always sufficient for the formatted string. If the buffer size of `hw_id_str` is less than expected, it may lead to buffer overflow, potentially allowing attackers to overwrite adjacent memory.",
        "code": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\ttrans_pcie->def_rx_queue = 0;\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\tpci_set_master(pdev);\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t}\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\treturn trans;\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "file_name": "209955.sol"
    },
    {
        "function_name": "iwl_trans_pcie_alloc",
        "vulnerability": "Null pointer dereference",
        "criticism": "This reasoning is similar to the first vulnerability, identifying a potential null pointer dereference if `pcim_iomap_table(pdev)[0]` is NULL. The code does check for this condition immediately after assignment, which reduces the risk. The reasoning is correct in identifying the potential issue, but the severity is overstated due to the existing check. The profitability remains low as it doesn't lead to a security breach.",
        "correctness": 7,
        "severity": 5,
        "profitability": 2,
        "reason": "If `pcim_iomap_table(pdev)[0]` returns NULL, `trans_pcie->hw_base` will be set to NULL. While there is a check immediately following this assignment, it can lead to a null pointer dereference if not handled properly before accessing `trans_pcie->hw_base` elsewhere in the code.",
        "code": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\ttrans_pcie->def_rx_queue = 0;\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\tpci_set_master(pdev);\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t}\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\treturn trans;\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "file_name": "209955.sol"
    },
    {
        "function_name": "iwl_trans_pcie_alloc",
        "vulnerability": "DMA mask handling",
        "criticism": "The reasoning correctly identifies the importance of handling DMA mask failures. The code does log an error and exit if no suitable DMA mask is available, which is appropriate handling. The reasoning is valid, but the severity is low as the code already handles the failure case. The profitability is low as it doesn't lead to a security breach.",
        "correctness": 8,
        "severity": 3,
        "profitability": 1,
        "reason": "This code attempts to set a DMA mask and consistent DMA mask for the device. If neither 64-bit nor 32-bit DMA masks are supported (`ret` is non-zero after these calls), the function logs an error and exits. However, failing to properly handle DMA mask failures could lead to undefined behavior or memory corruption if DMA operations are attempted subsequently.",
        "code": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\ttrans_pcie->def_rx_queue = 0;\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\tpci_set_master(pdev);\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t}\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\treturn trans;\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "file_name": "209955.sol"
    },
    {
        "function_name": "iwl_trans_pcie_alloc",
        "vulnerability": "Improper IRQ handling",
        "criticism": "The reasoning highlights a potential issue with shared IRQs, which can lead to race conditions if not properly managed. The code does request a shared IRQ, but without additional context, it's unclear if the device can handle shared interrupts. The reasoning is valid, and the severity is moderate due to potential denial-of-service, but the profitability is low as it requires specific conditions to exploit.",
        "correctness": 6,
        "severity": 5,
        "profitability": 2,
        "reason": "Requesting a shared interrupt line (`IRQF_SHARED`) without ensuring that the device can properly handle shared interrupts may lead to race conditions or interrupt handling issues. If the interrupt is not correctly managed, it could result in denial-of-service or unpredictable behavior.",
        "code": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\ttrans_pcie->def_rx_queue = 0;\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\tpci_set_master(pdev);\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t}\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\treturn trans;\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "file_name": "209955.sol"
    }
]