[
    {
        "function_name": "ConcatShapeHelper",
        "vulnerability": "Integer Overflow",
        "criticism": "The reasoning suggests that casting from int32 to int64 could lead to integer overflow. However, this is not accurate because int64 is a larger type than int32, and the conversion itself does not cause overflow. The real concern would be if the int32 value was used in a context where it could exceed int32 limits, but the conversion to int64 inherently prevents overflow. Therefore, the reasoning is incorrect. The severity and profitability are low because the conversion itself is safe.",
        "correctness": 2,
        "severity": 1,
        "profitability": 1,
        "reason": "The code does not properly check bounds when casting from int32 to int64, which could lead to integer overflow if the input tensor contains large values. An attacker could exploit this by providing malicious input that causes the system to produce incorrect results or crash.",
        "code": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  \n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "file_name": "224570.sol"
    },
    {
        "function_name": "ConcatShapeHelper",
        "vulnerability": "Improper Handling of Negative Indices",
        "criticism": "The reasoning points out that negative indices might lead to unexpected behavior. The code does handle negative indices by using them to calculate min_rank, but it does not ensure that concat_dim is within valid bounds. This could potentially lead to logic errors, but the code does not directly access memory based on concat_dim, reducing the risk of severe issues like segmentation faults. The severity is moderate due to potential logic errors, but profitability is low as exploitation is unlikely.",
        "correctness": 6,
        "severity": 4,
        "profitability": 2,
        "reason": "The use of concat_dim < 0 to handle negative indices might result in unexpected behavior, as it does not ensure that concat_dim is within valid bounds. Negative values could lead to accessing invalid memory or result in segmentation faults, enabling Denial of Service attacks.",
        "code": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  \n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "file_name": "224570.sol"
    },
    {
        "function_name": "ConcatShapeHelper",
        "vulnerability": "Unchecked Input Dimensions",
        "criticism": "The reasoning claims that the loop does not validate input dimensions, potentially leading to buffer overflows. However, the code uses WithRankAtLeast and Subshape functions, which perform checks on the input dimensions. Therefore, the reasoning is incorrect as the code does include dimension validation. The severity and profitability are low because the described vulnerability does not exist.",
        "correctness": 1,
        "severity": 1,
        "profitability": 1,
        "reason": "The loop does not adequately validate the dimensions of each input tensor, which could allow an attacker to cause buffer overflows or memory corruption by providing tensors with unexpected dimensions. This lack of validation could be exploited to execute arbitrary code or crash the system.",
        "code": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  \n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "file_name": "224570.sol"
    },
    {
        "function_name": "ConcatShapeHelper",
        "vulnerability": "Integer Conversion and Overflow",
        "criticism": "The reasoning suggests that converting from int32 to int64 without checking for overflows could lead to issues. However, as previously mentioned, int64 can safely store any int32 value without overflow. The concern about negative values is more about logic errors than overflow. The severity is low because the conversion itself is safe, and profitability is low as exploitation is unlikely.",
        "correctness": 3,
        "severity": 2,
        "profitability": 1,
        "reason": "The code performs a conversion from int32 to int64 without checking for potential overflows. If an attacker controls the input, they can provide an int32 that converts to a negative value or an unintended large value in int64, which could lead to incorrect behavior or exploitation, especially if the converted value is used for critical operations such as memory allocation or indexing.",
        "code": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  \n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "file_name": "224570.sol"
    },
    {
        "function_name": "ConcatShapeHelper",
        "vulnerability": "Negative Index Usage",
        "criticism": "The reasoning highlights a potential issue with negating concat_dim if it is INT64_MIN, which could cause overflow. This is a valid concern, as negating INT64_MIN would indeed cause overflow. However, the code does not directly use concat_dim for memory access, reducing the severity. The profitability is low because exploiting this would be challenging without direct memory access.",
        "correctness": 7,
        "severity": 3,
        "profitability": 2,
        "reason": "The calculation of 'min_rank' does not properly handle negative values of 'concat_dim'. If 'concat_dim' is negative, the logic attempts to negate the value, which can lead to unexpected results if the value is INT64_MIN due to integer overflow. This could be exploited to cause out-of-bounds access or other logic errors in the program.",
        "code": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  \n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "file_name": "224570.sol"
    },
    {
        "function_name": "ConcatShapeHelper",
        "vulnerability": "Improper Rank Validation",
        "criticism": "The reasoning correctly identifies that using a negative min_rank could lead to improper validation of input shapes. This is a valid concern, as it could allow malformed tensors to pass through. The severity is moderate because it could lead to logic errors, but profitability is low as it does not directly lead to security vulnerabilities.",
        "correctness": 8,
        "severity": 4,
        "profitability": 2,
        "reason": "The function 'WithRankAtLeast' is called with 'min_rank', which could be a negative value if 'concat_dim' is negative. This may lead to improper validation of 'input' shapes, potentially allowing shapes with fewer dimensions than expected. An attacker could exploit this to pass malformed tensors to subsequent operations, possibly triggering undefined behavior or security vulnerabilities.",
        "code": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  \n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "file_name": "224570.sol"
    }
]