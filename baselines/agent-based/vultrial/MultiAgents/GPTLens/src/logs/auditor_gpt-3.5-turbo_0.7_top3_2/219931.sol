[
    {
        "function_name": "EvaluateOneFoldable",
        "code": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "vulnerability": "Lack of input validation",
        "reason": "The code does not check if the 'value' attribute exists in the input node before accessing it. This can lead to a potential null pointer dereference if the attribute does not exist, causing a crash or unexpected behavior.",
        "file_name": "219931.sol"
    },
    {
        "function_name": "EvaluateOneFoldable",
        "code": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "vulnerability": "Potential memory leak",
        "reason": "The code dynamically allocates memory for 'value' but does not always properly clean it up. If an error occurs before the memory is deallocated, it can lead to a memory leak, consuming system resources over time.",
        "file_name": "219931.sol"
    },
    {
        "function_name": "EvaluateOneFoldable",
        "code": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "vulnerability": "Incomplete error handling",
        "reason": "The code breaks out of the loop if the input_tensor index is less than 0 without raising an error or providing any information about the issue. This can lead to silent failures and make it difficult to diagnose problems during runtime.",
        "file_name": "219931.sol"
    },
    {
        "function_name": "EvaluateOneFoldable",
        "code": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "vulnerability": "Integer Overflow",
        "reason": "The condition 'input_tensor.index() < 0' can lead to an integer overflow if the input tensor index is a very large positive number. This could potentially allow an attacker to bypass the loop intended to iterate over inputs, leading to unexpected behavior or memory corruption.",
        "file_name": "219931.sol"
    },
    {
        "function_name": "EvaluateOneFoldable",
        "code": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "vulnerability": "Double Free",
        "reason": "The code snippet 'delete(value);' can potentially lead to a double free vulnerability if 'value' is already deleted or freed earlier in the code. This could be exploited by an attacker to manipulate memory allocation and potentially execute arbitrary code.",
        "file_name": "219931.sol"
    },
    {
        "function_name": "EvaluateOneFoldable",
        "code": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "vulnerability": "Out-of-Bounds Write",
        "reason": "The code snippet 'outputs->resize(output_tensors.size());' can result in an out-of-bounds write if 'output_tensors.size()' exceeds the capacity of 'outputs'. This could be exploited by an attacker to overwrite adjacent memory locations and potentially gain control over the program's execution flow.",
        "file_name": "219931.sol"
    }
]